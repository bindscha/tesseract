//// Created by jasmi on 7/1/2019.//#include "libtesseract.h"#include "graph.hpp"#include <thread>#include <random>#include <algorithm>#include <iostream>#include <fstream>#include <unordered_set>bool _mmap = false;bool indexed = false;int c;std::string tmp;size_t NO_UP = 1000;size_t b_size = 0,initial_chunk = 0;std::unordered_set<uint64_t> update_idx;void generateUpdateIdx(uint64_t noUpdates, uint64_t _NB_EDGES,edge_full* e){    uint64_t no_ups = 0;    unsigned seed = std::chrono::system_clock::now().time_since_epoch().count();    std::mt19937 generator (seed);    uint64_t curr_edge   = _NB_EDGES - noUpdates;    uint64_t pivot = 1;    std::cout <<"Sorted updates\n";//    while(update_idx.size() < noUpdates){//        uint64_t val = curr_edge;//////        if(e[val].src < e[val].dst) {//            assert(val >= 0 && val < _NB_EDGES);//            update_idx.insert(val);//        }//        curr_edge+= pivot;//        if(curr_edge == _NB_EDGES){//            std::cout <<"Inserted "<<update_idx.size() <<" going back now\n";//            pivot = -1;//            curr_edge = _NB_EDGES - no_ups - 1;//        }////    }    while(update_idx.size() < noUpdates ){        uint64_t val = generator();// RANDOM UPS//        uint64_t val = curr_edge - 1;        if(val > _NB_EDGES - 1){            val = val % (_NB_EDGES  - 1);        }        if(e[val].src < e[val].dst) {            update_idx.insert(val);        }//        curr_edge++;//        if(curr_edge == _NB_EDGES){//            curr_edge = generator();//        }    }}int main(int argc, char** argv)  {    std::string update_file ;    bool up_file  = false;    Configuration* configuration = new Configuration();    GraphInputFiles* graphInput = new GraphInputFiles();    bool del = false;    while ((c = getopt(argc, argv, "f:d:n:t:b:uc:a:rp:")) != -1) {        switch (c) {            case 'f':                graphInput->input_file = optarg;                break;            case 'd':                graphInput->degree_file = optarg;                break;            case 'i':                indexed = true; //exp_mode[atoi(optarg)];                break;            case 'n':                tmp = std::string(optarg);                graphInput->nb_nodes = stoul(tmp);//                NB_NODES = stoul(tmp);                break;            case 't':                tmp = std::string(optarg);                configuration->no_threads = stoul(tmp);                break;            case 'b':                tmp = std::string(optarg);                b_size = stoul(tmp);                printf("Update batch size %lu\n", b_size);                break;            case 'u':                do_updates = 1;                printf("Running updates \n");                break;            case 'c':                tmp = std::string(optarg);                initial_chunk = stoul(tmp); //preload initial_chunk updates before starting to apply updates                printf("Preloading %lu updates\n ", initial_chunk);                break;            case 'r': //UPDATES ARE REMOVALS                updateType = GraphUpdateType::EdgeDel;                printf("Deleting edges \n");                del = true;                break;            case 'a': //Algo                configuration->algorithm_id = atoi(optarg);                break;            case 'p':                update_file = std::string(optarg);                up_file = true;                break;//            case 'm'://                _mmap = true;//                printf("MMAP-ing input and output\n");//                break;        }    }    configuration->worker_id = 0;    configuration->num_workers = 1;    //For single machine case with a file as input:    setGraphInputFiles(graphInput);    if(do_updates)        init_update_buf(b_size, NB_EDGES, NB_NODES, 1, del? NB_EDGES :initial_chunk);    if(initial_chunk == 0)     init(configuration);    std::thread engine_th;    if(initial_chunk ==0)       engine_th = std::thread(start); //start  Engine    if(do_updates){//        initial_chunk = NB_EDGES ;//        if(NO_UP > NB_EDGES )            NO_UP = NB_EDGES;//        std::vector<uint64_t> v(NB_EDGES);////#pragma omp parallel for num_threads(56)//            for(size_t i = 0; i < NB_EDGES;i++){//                v[i] = i;//            }////        std::random_shuffle(v.begin(), v.end());////////        for(size_t i =0 ; i < NB_EDGES;i++){//            printf("%u\t%u\n",edges_full[v.at(i)].src,edges_full[v.at(i)].dst);//        }//        exit(1);//        int fd_shuffle = open("/media/nvme/sosp2019_inputs/twitter_sym_shuffled", O_RDWR | O_CREAT | O_LARGEFILE|O_NOATIME, 0600);//        if(fd_shuffle == -1 ){//            perror("Failed to open file\n");//        }//        else{//            size_t to_mmap = NB_EDGES * sizeof(edge_full);//            if(to_mmap %4096 != 0){//                to_mmap = to_mmap + 4096 - NB_EDGES % 4096;//            }//            fallocate(fd_shuffle, 0, 0, to_mmap);//            edge_full* e_shuffled = (edge_full*) mmap(NULL,to_mmap, PROT_READ | PROT_WRITE, MAP_SHARED, fd_shuffle, 0);//            if(e_shuffled == MAP_FAILED){//                perror("Failed to mmap\n");//                exit(1);//            }//#pragma omp parallel for num_threads(56)//            for(size_t i = 0; i < NB_EDGES; i++){//                e_shuffled[i].src = edges_full[v.at(i)].src;//                e_shuffled[i].dst = edges_full[v.at(i)].dst;//            }////            msync(e_shuffled,to_mmap, MS_SYNC);//            ftruncate(fd_shuffle,NB_EDGES *sizeof(edge_full));//            munmap(e_shuffled, to_mmap);//            close(fd_shuffle);//            exit(1);////        }//        exit(1);        if(initial_chunk != 0 ){            generateUpdateIdx(2000000, NB_EDGES,edges_full);            initial_chunk = preloadChunk(del?NB_EDGES:initial_chunk,configuration,update_idx); // If deletions, load the entire graph            printf("New` initial chunk %lu\n",initial_chunk);            init(configuration);            engine_th = std::thread(start);            printf("Done preloading\n");        }//        int fd = open(update_file, O_RDWR);//        if(fd == -1) {//            perror("Failed to open input file");//            exit(1);//        }//        struct stat sb;//        fstat(fd, &sb);//        size_t b_read = 0;//        while(b_read <sb.st_size){//            size_t b_r = read(fd, edges_full+b_read/sizeof(struct edge_full), sb.st_size - b_read);//            assert(b_r!=-1);//            b_read += b_r;//        }        struct edge_full *updates = NULL;//if(up_file) {//    std::ifstream file(update_file);//    if (!file) {//        std::cout << "unable to open file";//        exit(1);//    }////    updates = (struct edge_full *) malloc(NO_UP * sizeof(edge_full));////        NO_UP = b_read /sizeof(struct edge_full);//    printf("*** Applying %lu updates\n", NO_UP);//    std::string s;//    uint32_t src, dst;//    size_t idx = 0;//    while (file >> src >> dst) {//        updates[idx].src = src;//        updates[idx].dst = dst;//        idx++;//        bool found = 0;//        for (size_t i = 0; i < degree[src]; i++) {//            if (edges[adj_offsets[src] + i].dst == dst) {//                edges[adj_offsets[src] + i].ts = NB_EDGES;//                found = 1;//                break;//            }//        }////        if (!found) {//            printf("1.Searching for %u in %u\n", src, dst);//        }//        assert(found);//        found = 0;//        for (size_t i = 0; i < degree[dst]; i++) {//            if (edges[adj_offsets[dst] + i].dst == src) {//                edges[adj_offsets[dst] + i].ts = NB_EDGES;//                found = 1;//                break;//            }//        }//        if (!found) {//            printf("Searching for %u in %u\n", src, dst);//        }////        assert(found);//        char next;//        file.get(next);//    }//}        GraphUpdate* update_stream = new GraphUpdate[b_size];        size_t no_batches = 1;        size_t total_added = 0;//        for(size_t j = NB_EDGES -1; total_added < initial_chunk && j >= 0; ){ //DELETE EDGES AT END//            size_t items_added = 0;//            size_t i = 0;//            for(; items_added < b_size && j >= 0; j--){//} i++){//                if(edges_full[j ].src > edges_full[j].dst)continue;////                if(edges_full[j ].src != 0)continue;//                update_stream[items_added].src = edges_full[j].src;//                update_stream[items_added].dst = edges_full[j].dst;//                update_stream[items_added].ts = no_batches;//                update_stream[items_added].tpe = del?EdgeDel: EdgeAdd;//                items_added++;//                total_added++;//                if(total_added == initial_chunk) break;//            }////            j-=i;////            total_added += items_added;//            printf("Processed %lu of %lu (%lu) ^^^\n ", items_added, j, NB_EDGES);//            no_batches++;//            batch_new(update_stream, items_added);//            if(total_added == initial_chunk) break;//        }//        int update_fd = open("/media/nvme/sosp2019_inputs/uk/uk_updates",O_RDONLY | O_CREAT | O_LARGEFILE|O_NOATIME, 0600);//        struct edge_full* updates = (edge_full*) malloc(NO_UP * sizeof(edge_full));//        size_t b_read = read(update_fd,updates, NO_UP *sizeof(edge_full));////        assert (b_read == NO_UP * sizeof(edge_full));//        NO_UP    = b_read / sizeof(edge_full);//        for(size_t j = 0 ; j < NO_UP;j++){//            uint32_t src = updates[j].src;//            uint32_t dst = updates[j].dst;////            for(size_t i =0 ;i < degree[src];i++){//                uint32_t d = edges[adj_offsets[src]+i].dst;//                if(d == dst){//                    edges[adj_offsets[src] + i].ts = UINT64_MAX;//                    degree[src]--;//                    break;//                }//            }//            for(size_t i =0 ;i < degree[dst];i++){//                uint32_t d = edges[adj_offsets[dst]+i].dst;//                if(d == src){//                    edges[adj_offsets[dst] + i].ts = UINT64_MAX;//                    degree[dst]--;//                    break;//                }//            }////        }        uint64_t ups_added = 0;        std::cout<<"adding " << (initial_chunk ? update_idx.size() : NB_EDGES )<< "updates \n";        if(initial_chunk) {            for (uint64_t idx: update_idx) {                update_stream[ups_added].src = edges_full[idx].src;                update_stream[ups_added].dst = edges_full[idx].dst;                update_stream[ups_added].ts = no_batches;                update_stream[ups_added].tpe = del ? EdgeDel : EdgeAdd;                ups_added++;                if (ups_added == b_size) {                    printf("Processed %lu of %lu (%lu) ^^^\n ", ups_added * no_batches, update_idx.size(), NB_EDGES);                    no_batches++;                    batch_new(update_stream, ups_added);                    ups_added = 0;                }            }        }        else{            for(size_t idx = 0; idx < NB_EDGES; idx++){                if(edges_full[idx].src > edges_full[idx].dst) continue;                assert(edges_full[idx].src != edges_full[idx].dst);                update_stream[ups_added].src = edges_full[idx].src;                update_stream[ups_added].dst = edges_full[idx].dst;                update_stream[ups_added].ts = no_batches;                update_stream[ups_added].tpe = del ? EdgeDel : EdgeAdd;                ups_added++;                if (ups_added == b_size) {                    printf("Processed %lu of %lu (%lu) ^^^\n ", ups_added * no_batches, update_idx.size(), NB_EDGES);                    no_batches++;                    batch_new(update_stream, ups_added);                    ups_added = 0;                }            }            if(ups_added){                printf("Processed %lu of %lu (%lu) ^^^\n ", ups_added * no_batches, update_idx.size(), NB_EDGES);                no_batches++;                batch_new(update_stream, ups_added);                ups_added = 0;            }        }        /*        for(size_t j = del?0 : initial_chunk; del? (j < initial_chunk|| j<NB_EDGES) : j< NB_EDGES;  ){ //Deletes/Adds first INITIAL_CHUNK_EDGES//            for(size_t j = 0; j < NO_UP;j++){            if(j + b_size > NB_EDGES) b_size = NB_EDGES - j;            volatile size_t items_added = 0;            for( ;items_added < b_size && j < NB_EDGES ; j++ ) {//                if(j - initial_chunk  < 10){//                    printf("Adding %lu\n",v->at(j));//                }////                if(edges_full[j].src > edges_full[j].dst) continue;//.at(j) ].dst) continue;//                assert(edges_full[j].src < NB_NODES);//                assert(edges_full[j].dst < NB_NODES);//                if(edges_full[v[j]].src > edges_full[v[j] ].dst) {//                    continue;//                }//                if(edges_full[j].src != 0 )continue;                if (up_file) {                    if (updates[j].src > updates[j].dst) {                        update_stream[items_added].src = updates[j].dst;                        update_stream[items_added].dst = updates[j].src;                    } else {                        update_stream[items_added].src = updates[j].src;                        update_stream[items_added].dst = updates[j].dst;                    }                } else {                    if (edges_full[j].src > edges_full[j].dst) continue;//                    if (edges_full[v[j]].src > edges_full[v[j]].dst) continue;//                    update_stream[items_added].src = edges_full[v[j]].src;//                    update_stream[items_added].dst = edges_full[v[j]].dst;                    update_stream[items_added].src = edges_full[j].src;                    update_stream[items_added].dst = edges_full[j].dst;                }                    update_stream[items_added].ts = no_batches;                    update_stream[items_added].tpe = del ? EdgeDel : EdgeAdd;                    items_added++;                    total_added++;                    if (del && total_added == initial_chunk) break;            }            printf("Processed %lu of %lu (%lu) ^^^\n ", items_added, j, NB_EDGES);            no_batches++;            batch_new(update_stream, items_added);//            if(total_added == NB_EDGES) break;        }*/        //Start update engine    }    stop();    engine_th.join();//    init_tesseract(0, 1, _mmap);//    start_exec();    return 0;}